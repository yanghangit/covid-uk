{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-03-01'\n",
    "end_date = '2022-03-31'\n",
    "long_term_exposure_years = 5\n",
    "N_neighbors_spatial_interpolation = 3\n",
    "N_neighbors_temporal_interpolation = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_2020 = pd.read_csv(os.path.join(\"mobility\", \"2020_GB_Region_mobility_report.csv\"))\n",
    "mobility_2021 = pd.read_csv(os.path.join(\"mobility\", \"2021_GB_Region_mobility_report.csv\"))\n",
    "mobility_2022 = pd.read_csv(os.path.join(\"mobility\", \"2022_GB_Region_mobility_report.csv\"))\n",
    "\n",
    "mobility_df = pd.concat([mobility_2020, mobility_2021, mobility_2022], axis=0)\n",
    "mobility_variables = ['retail_and_recreation_percent_change_from_baseline',\n",
    "                      'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                      'parks_percent_change_from_baseline',\n",
    "                      'transit_stations_percent_change_from_baseline',\n",
    "                      'workplaces_percent_change_from_baseline',\n",
    "                      'residential_percent_change_from_baseline']\n",
    "mobility_df = mobility_df[['sub_region_1', 'sub_region_2', 'date'] + mobility_variables]\n",
    "mobility_df['date'] = pd.to_datetime(mobility_df['date'])\n",
    "mobility_df = mobility_df[(mobility_df[\"date\"] >= start_date)& (mobility_df[\"date\"] <= end_date)]\n",
    "mobility_df['date'] = mobility_df['date'].dt.strftime('%Y-%m-%d')\n",
    "mobility_df = mobility_df[~mobility_df['sub_region_1'].isnull()]\n",
    "\n",
    "replace_values = mobility_df.loc[mobility_df['sub_region_2'] == 'Suffolk Coastal District', 'sub_region_2'].str.replace('Suffolk Coastal', 'East Suffolk')\n",
    "mobility_df.loc[mobility_df['sub_region_2'] == 'Suffolk Coastal District', 'sub_region_2'] = replace_values\n",
    "\n",
    "replace_values = mobility_df.loc[mobility_df['sub_region_2'] == 'Waveney District', 'sub_region_2'].str.replace('Waveney', 'East Suffolk')\n",
    "mobility_df.loc[mobility_df['sub_region_2'] == 'Waveney District', 'sub_region_2'] = replace_values\n",
    "\n",
    "replace_values = mobility_df.loc[mobility_df['sub_region_2'] == 'London Borough of Hackney', 'sub_region_2'].str.replace('London Borough of Hackney', 'Hackney and City of London')\n",
    "mobility_df.loc[mobility_df['sub_region_2'] == 'London Borough of Hackney', 'sub_region_2'] = replace_values\n",
    "\n",
    "replace_values = mobility_df.loc[mobility_df['sub_region_2'] == 'City of London', 'sub_region_2'].str.replace('City of London', 'Hackney and City of London')\n",
    "mobility_df.loc[mobility_df['sub_region_2'] == 'City of London', 'sub_region_2'] = replace_values\n",
    "\n",
    "mobility_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltlas_gdf = gpd.GeoDataFrame.from_file(os.path.join(\"gis\", 'lad19.geojson'))\n",
    "districts = pd.unique(ltlas_gdf['district_name'])\n",
    "district_ids = pd.unique(ltlas_gdf['district_id'])\n",
    "ltlas_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = {}\n",
    "in_region_1 = []\n",
    "missing_district_upsampling_map = {\n",
    "    \"Cornwall and Isles of Scilly\": \"Cornwall\",\n",
    "}\n",
    "for district_name in pd.unique(ltlas_gdf['district_name']):\n",
    "    regions_1 = pd.unique(mobility_df['sub_region_1'])\n",
    "    regions_2 = pd.unique(mobility_df['sub_region_2'])\n",
    "    if district_name not in regions_2:\n",
    "        if district_name == \"Kingston upon Hull, City of\":\n",
    "            name_mapping[\"Kingston upon Hull\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"Bristol, City of\":\n",
    "            name_mapping[\"Bristol City\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"Herefordshire, County of\":\n",
    "            name_mapping[\"Herefordshire\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"Folkestone and Hythe\":\n",
    "            name_mapping[\"Folkestone & Hythe District\"] = district_name\n",
    "\n",
    "        elif district_name == \"St Albans\":\n",
    "            name_mapping[\"Saint Albans District\"] = district_name\n",
    "\n",
    "        elif district_name == \"St. Helens\":\n",
    "            name_mapping[\"Metropolitan Borough of St Helens\"] = district_name\n",
    "\n",
    "        elif district_name == \"Derry City and Strabane\":\n",
    "            name_mapping[\"Derry and Strabane\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"Na h-Eileanan Siar\":\n",
    "            name_mapping[\"Na h-Eileanan an Iar\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"Orkney Islands\":\n",
    "            name_mapping[\"Orkney\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"City of Edinburgh\":\n",
    "            name_mapping[\"Edinburgh\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name == \"Somerset West and Taunton\":\n",
    "            name_mapping[\"Taunton Deane\"] = district_name\n",
    "            name_mapping[\"West Somerset District\"] = district_name\n",
    "\n",
    "        elif district_name == \"Rhondda Cynon Taf\":\n",
    "            name_mapping[\"Rhondda Cynon Taff\"] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"%s District\" % district_name in regions_2:\n",
    "            name_mapping[\"%s District\" % district_name] = district_name\n",
    "        elif \"%s District\" % district_name in regions_1:\n",
    "            name_mapping[\"%s District\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"%s Borough\" % district_name in regions_2:\n",
    "            name_mapping[\"%s Borough\" % district_name] = district_name\n",
    "        elif \"%s Borough\" % district_name in regions_1:\n",
    "            name_mapping[\"%s Borough\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"%s County Borough\" % district_name in regions_2:\n",
    "            name_mapping[\"%s County Borough\" % district_name] = district_name\n",
    "        elif \"%s County Borough\" % district_name in regions_1:\n",
    "            name_mapping[\"%s County Borough\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"Borough of %s\" % district_name in regions_2:\n",
    "            name_mapping[\"Borough of %s\" % district_name] = district_name\n",
    "        elif \"Borough of %s\" % district_name in regions_1:\n",
    "            name_mapping[\"Borough of %s\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"Metropolitan Borough of %s\" % district_name in regions_2:\n",
    "            name_mapping[\"Metropolitan Borough of %s\" %\n",
    "                         district_name] = district_name\n",
    "        elif \"Metropolitan Borough of %s\" % district_name in regions_1:\n",
    "            name_mapping[\"Metropolitan Borough of %s\" %\n",
    "                         district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"London Borough of %s\" % district_name in regions_2:\n",
    "            name_mapping[\"London Borough of %s\" %\n",
    "                         district_name] = district_name\n",
    "        elif \"London Borough of %s\" % district_name in regions_1:\n",
    "            name_mapping[\"London Borough of %s\" %\n",
    "                         district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"Royal Borough of %s\" % district_name in regions_2:\n",
    "            name_mapping[\"Royal Borough of %s\" % district_name] = district_name\n",
    "        elif \"Royal Borough of %s\" % district_name in regions_1:\n",
    "            name_mapping[\"Royal Borough of %s\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"City of %s\" % district_name in regions_2:\n",
    "            name_mapping[\"City of %s\" % district_name] = district_name\n",
    "        elif \"City of %s\" % district_name in regions_1:\n",
    "            name_mapping[\"City of %s\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"City of %s District\" % district_name in regions_2:\n",
    "            name_mapping[\"City of %s District\" % district_name] = district_name\n",
    "        elif \"City of %s District\" % district_name in regions_1:\n",
    "            name_mapping[\"City of %s District\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"%s Council\" % district_name in regions_2:\n",
    "            name_mapping[\"%s Council\" % district_name] = district_name\n",
    "        elif \"%s Council\" % district_name in regions_1:\n",
    "            name_mapping[\"%s Council\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"%s Principal Area\" % district_name in regions_2:\n",
    "            name_mapping[\"%s Principal Area\" % district_name] = district_name\n",
    "        elif \"%s Principal Area\" % district_name in regions_1:\n",
    "            name_mapping[\"%s Principal Area\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif \"%s Principle Area\" % district_name in regions_2:\n",
    "            name_mapping[\"%s Principle Area\" % district_name] = district_name\n",
    "        elif \"%s Principle Area\" % district_name in regions_1:\n",
    "            name_mapping[\"%s Principle Area\" % district_name] = district_name\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name in regions_1:\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        elif district_name in missing_district_upsampling_map:\n",
    "            in_region_1.append(district_name)\n",
    "\n",
    "        else:\n",
    "            print(district_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_df['sub_region_1'] = mobility_df['sub_region_1'].replace(name_mapping)\n",
    "mobility_df['sub_region_2'] = mobility_df['sub_region_2'].replace(name_mapping)\n",
    "mobility_df = mobility_df.groupby(['date', 'sub_region_1', 'sub_region_2'], dropna=False)[mobility_variables].mean().reset_index()\n",
    "\n",
    "mobility_df_2 = mobility_df[~((mobility_df['sub_region_1'].isin(in_region_1)) & (mobility_df['sub_region_2'].isnull()))]\n",
    "mobility_df_1 = mobility_df[(mobility_df['sub_region_1'].isin(in_region_1)) & (mobility_df['sub_region_2'].isnull())]\n",
    "ltlas_gdf_2 = ltlas_gdf[~ltlas_gdf['district_name'].isin(in_region_1)]\n",
    "ltlas_gdf_1 = ltlas_gdf[ltlas_gdf['district_name'].isin(in_region_1)]\n",
    "\n",
    "mobility_df_2_merged = pd.merge(mobility_df_2, ltlas_gdf_2, left_on=\"sub_region_2\", right_on=\"district_name\", how=\"right\")\n",
    "mobility_df_1_merged = pd.merge(mobility_df_1, ltlas_gdf_1, left_on=\"sub_region_1\", right_on=\"district_name\", how=\"right\")\n",
    "\n",
    "mobility_df_merged = pd.concat([mobility_df_2_merged, mobility_df_1_merged], axis=0)\n",
    "mobility_df_merged = mobility_df_merged[['district_id', 'district_name', 'date'] + mobility_variables]\n",
    "mobility_df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "new_records = []\n",
    "for district_name in districts:\n",
    "    district_df = mobility_df_merged[mobility_df_merged['district_name']== district_name]\n",
    "    district_id = district_df['district_id'].values[0]\n",
    "    if len(dates) != len(pd.unique(district_df['date'])):\n",
    "        for date in dates:\n",
    "            if date.strftime('%Y-%m-%d') not in district_df['date'].unique():\n",
    "                new_record = {\n",
    "                    'district_id': district_id,\n",
    "                    'district_name': district_name,\n",
    "                    'date': date.strftime('%Y-%m-%d')\n",
    "                }\n",
    "                for mobility_variable in mobility_variables:\n",
    "                    new_record[mobility_variable] = np.nan\n",
    "                new_records.append(new_record)\n",
    "\n",
    "missing_records_df = pd.DataFrame.from_records(new_records)\n",
    "mobility_ltla_gdf = pd.concat([mobility_df_merged[~mobility_df_merged['district_name'].isin(\n",
    "    missing_district_upsampling_map.keys())], missing_records_df], axis=0)\n",
    "mobility_ltla_gdf = mobility_ltla_gdf.sort_values(['district_name', 'date'])\n",
    "mobility_ltla_gdf = mobility_ltla_gdf.reset_index()\n",
    "mobility_ltla_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no date is missing for each district\n",
    "for district in districts:\n",
    "    assert(len(dates) == len(mobility_ltla_gdf[mobility_ltla_gdf['district_name'] == district]['date'].unique()))\n",
    "\n",
    "# make sure no district is missing for each date\n",
    "for date in dates:\n",
    "    one_day_df = mobility_ltla_gdf[mobility_ltla_gdf['date'] == date.strftime('%Y-%m-%d')]\n",
    "    assert(len(one_day_df['district_name'].unique()) == len(ltlas_gdf['district_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_district in missing_district_upsampling_map:\n",
    "    print(\"Upsampling missing values for district: %s \" % missing_district)\n",
    "    for mobility_variable in mobility_variables:\n",
    "        for date in dates:\n",
    "            date = date.strftime('%Y-%m-%d')\n",
    "            upsampled_district = missing_district_upsampling_map[missing_district]\n",
    "            upsampled_value = mobility_df[(mobility_df['date'] == date) & (\n",
    "                mobility_df['sub_region_1'] == upsampled_district)][mobility_variable].values[0]\n",
    "            if upsampled_value:\n",
    "                mobility_ltla_gdf.loc[(mobility_ltla_gdf['date'] == date) & (\n",
    "                    mobility_ltla_gdf['district_name'] == missing_district), mobility_variable] = mobility_ltla_gdf.loc[(mobility_ltla_gdf['date'] == date) & (\n",
    "                        mobility_ltla_gdf['district_name'] == missing_district), mobility_variable].fillna(value=upsampled_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal interpolation\n",
    "for district in mobility_ltla_gdf['district_name'].unique():\n",
    "    for mobility_variable in mobility_variables:\n",
    "        district_df = mobility_ltla_gdf[mobility_ltla_gdf['district_name'] == district].reset_index().copy()\n",
    "        mobility_values = district_df[mobility_variable].interpolate(method=\"linear\", limit=N_neighbors_temporal_interpolation)\n",
    "        mobility_ltla_gdf.loc[(mobility_ltla_gdf['district_name'] == district), mobility_variable] = mobility_ltla_gdf.loc[(\n",
    "            mobility_ltla_gdf['district_name'] == district), mobility_variable].fillna(value=mobility_values)\n",
    "mobility_ltla_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial interpolation\n",
    "def spatial_distance(X1, X2, missing_values=None):\n",
    "    # X: ..., 'district_lon', 'district_lat'\n",
    "    return scipy.spatial.distance.euclidean(X1[-2:], X2[-2:])\n",
    "\n",
    "\n",
    "mobility_ltla_gdf = pd.merge(mobility_ltla_gdf, ltlas_gdf, left_on=(\n",
    "    \"district_name\", 'district_id'), right_on=(\"district_name\", \"district_id\"), how=\"left\")\n",
    "mobility_ltla_gdf = mobility_ltla_gdf[[\n",
    "    'date', 'district_name', 'district_id'] + mobility_variables + ['district_lon', 'district_lat']]\n",
    "for date in tqdm(dates, desc=\"Mobility data spatial interpolation\"):\n",
    "    date = date.strftime('%Y-%m-%d')\n",
    "    mobility_matrix = mobility_ltla_gdf[mobility_ltla_gdf['date'] == date][mobility_variables + ['district_lon', 'district_lat']]\n",
    "    imputer = KNNImputer(n_neighbors=N_neighbors_spatial_interpolation, weights='distance', metric=spatial_distance)\n",
    "    imputed_matrix = imputer.fit_transform(mobility_matrix)\n",
    "    imputed_df = pd.DataFrame(data=imputed_matrix[:, 0:len(\n",
    "        mobility_variables)], index=mobility_matrix.index, columns=mobility_variables)\n",
    "    mobility_ltla_gdf.loc[(mobility_ltla_gdf['date'] == date), mobility_variables] = mobility_ltla_gdf.loc[(\n",
    "        mobility_ltla_gdf['date'] == date), mobility_variables].fillna(value=imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_ltla_gdf = mobility_ltla_gdf.drop('district_lon', axis=1)\n",
    "mobility_ltla_gdf = mobility_ltla_gdf.drop('district_lat', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_ltla_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_mobility_data= scaler.fit_transform(mobility_ltla_gdf[mobility_variables])\n",
    "pca = PCA(.95)\n",
    "pca.fit(scaled_mobility_data)\n",
    "\n",
    "weight_vector = pca.explained_variance_ratio_ / pca.explained_variance_ratio_.sum()\n",
    "transformed_mobility = pca.transform(scaled_mobility_data)\n",
    "for idx, weight in enumerate(weight_vector):\n",
    "    transformed_mobility[:, idx] = transformed_mobility[:, idx] * weight\n",
    "mobility_ltla_gdf['mobility_index'] = transformed_mobility.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_ltla_gdf[mobility_variables + ['mobility_index']] = mobility_ltla_gdf[mobility_variables + ['mobility_index']].astype(float)\n",
    "mobility_ltla_gdf.to_csv(\"../mobility.csv\", float_format=\"%.1f\", na_rep=\"N/A\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "878ae0fd6e3254d26856d0042bf976ac5dcc346e75060cdd861132d9be011f18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
